{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omnious/workspace/jovis/jovis-model/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import faiss\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from jovis_model.config import Config\n",
    "from jovis_model.utils.helper import build_faiss_index\n",
    "from jovis_model.models.llm.mclip import CLIPModel\n",
    "from run import ModelRunner\n",
    "from jovis_model.utils.report import ReportMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# InternVL vs CLIP Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"pkg\": \"llm\",\n",
    "    \"task\": \"mclip\",\n",
    "    \"use_hf_model\": True,\n",
    "    \"params\": {\n",
    "        \"hf_name\": \"M-CLIP/XLM-Roberta-Large-Vit-B-32\"\n",
    "    }\n",
    "}\n",
    "config = Config(**params)\n",
    "model = CLIPModel(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = \"/data/local/multimodal_for_skb/images/skb\"\n",
    "# image_lst = glob(os.path.join(image_path, \"*.webp\"))\n",
    "\n",
    "# pids = []\n",
    "# embeddings = []\n",
    "# for img_path in tqdm(image_lst):\n",
    "#     pid = os.path.basename(img_path).split(\".\")[0]\n",
    "#     img = PIL.Image.open(img_path)\n",
    "#     embed = model.inference(img).detach().cpu().numpy()[0]\n",
    "#     pids.append(pid)\n",
    "#     embeddings.append(embed)\n",
    "# build_faiss_index(\n",
    "#     embeddings=embeddings,\n",
    "#     save_path=\"outputs/skb\",\n",
    "#     save_name=\"clip_image\",\n",
    "#     pids=pids\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jovis_model/_db/llm/multimodal/query.json\", \"r\") as f:\n",
    "    querys = json.load(f)\n",
    "ko_embeddings = model.inference(querys[\"ko\"])\n",
    "en_embeddings = model.inference(querys[\"en\"])\n",
    "# query_embeddings = model.inference([\"hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "querys[\"ko_embeddings\"] = ko_embeddings.detach().cpu().numpy().tolist()\n",
    "querys[\"en_embeddings\"] = en_embeddings.detach().cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/skb/clip_text_embeddings.json\", \"w\") as f:\n",
    "    json.dump(querys, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### InternVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"pkg\": \"llm\",\n",
    "    \"task\": \"internvl\",\n",
    "    \"use_hf_model\": True,\n",
    "    \"params\": {\n",
    "        \"hf_name\": \"OpenGVLab/InternVL-Chat-V1-5\",\n",
    "        \"max_new_tokens\": 512\n",
    "    }\n",
    "}\n",
    "config = Config(**params)\n",
    "runner = ModelRunner(\n",
    "    config=config,\n",
    "    mode=\"inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sentence Embedding : description & query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omnious/workspace/jovis/jovis-model/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"pkg\": \"llm\",\n",
    "    \"task\": \"sentence_embedding\",\n",
    "    \"use_hf_model\": True,\n",
    "    \"params\": {\n",
    "        \"hf_name\": \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    }\n",
    "}\n",
    "config = Config(**params)\n",
    "runner = ModelRunner(\n",
    "    config=config,\n",
    "    mode=\"inference\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jovis_model/_db/llm/multimodal/query.json\", \"r\") as f:\n",
    "    querys = json.load(f)\n",
    "\n",
    "ko_embeddings = runner.run(querys[\"ko\"])\n",
    "en_embeddings = runner.run(querys[\"en\"])\n",
    "querys[\"ko_embeddings\"] = ko_embeddings.detach().cpu().numpy().tolist()\n",
    "querys[\"en_embeddings\"] = en_embeddings.detach().cpu().numpy().tolist()\n",
    "with open(\"outputs/skb/query_text_embeddings.json\", \"w\") as f:\n",
    "    json.dump(querys, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/omnious/workspace/jovis/jovis-model/outputs/skb/descriptions_v2.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    descriptions = json.load(f)\n",
    "pids = []\n",
    "embeddings = []\n",
    "for pid, description in tqdm(descriptions.items()):\n",
    "    pids.append(pid)\n",
    "    embeddings.append(runner.run([description]).detach().cpu().numpy()[0])\n",
    "build_faiss_index(\n",
    "    embeddings=embeddings,\n",
    "    save_path=\"/home/omnious/workspace/jovis/jovis-model/outputs/skb\",\n",
    "    save_name=\"descriptions_v2\",\n",
    "    pids=pids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_index = faiss.read_index(\"outputs/skb/descriptions_v2.index\")\n",
    "clip_index = faiss.read_index(\"outputs/skb/clip_image.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/skb/clip_image_map.json\", \"r\") as f:\n",
    "    clip_image_map = json.load(f)\n",
    "\n",
    "with open(\"outputs/skb/descriptions_v2_map.json\", \"r\") as f:\n",
    "    ivl_desc_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/skb/clip_text_embeddings.json\", \"r\") as f:\n",
    "    clip_text_embeddings = json.load(f)\n",
    "\n",
    "with open(\"outputs/skb/query_text_embeddings.json\", \"r\") as f:\n",
    "    query_text_embeddings = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for idx, (ko_query, ko_clip_embed, ko_query_embed, en_query, en_clip_embed, en_query_embed) in enumerate(zip(\n",
    "        clip_text_embeddings[\"ko\"], clip_text_embeddings[\"ko_embeddings\"], query_text_embeddings[\"ko_embeddings\"],\n",
    "        clip_text_embeddings[\"en\"], clip_text_embeddings[\"en_embeddings\"], query_text_embeddings[\"en_embeddings\"]\n",
    "    )):\n",
    "    res[f\"query_{idx}\"] = defaultdict(list)\n",
    "    scores, ids = clip_index.search(np.array(ko_clip_embed).reshape(1, -1), 5)\n",
    "    scores = [\"[invl] {:.4f}\".format(s) for s in scores[0]]\n",
    "    ids = [clip_image_map[str(i)] for i in ids[0]]\n",
    "    res[f\"query_{idx}\"][ko_query].append({\"text\": scores, \"image\": ids})\n",
    "\n",
    "    scores, ids = desc_index.search(np.array(ko_query_embed).reshape(1, -1), 5)\n",
    "    scores = [\"[clip] {:.4f}\".format(s) for s in scores[0]]\n",
    "    ids = [ivl_desc_map[str(i)] for i in ids[0]]\n",
    "    res[f\"query_{idx}\"][ko_query].append({\"text\": scores, \"image\": ids})\n",
    "\n",
    "    scores, ids = clip_index.search(np.array(en_clip_embed).reshape(1, -1), 5)\n",
    "    scores = [\"[invl] {:.4f}\".format(s) for s in scores[0]]\n",
    "    ids = [clip_image_map[str(i)] for i in ids[0]]\n",
    "    res[f\"query_{idx}\"][en_query].append({\"text\": scores, \"image\": ids})\n",
    "\n",
    "    scores, ids = desc_index.search(np.array(en_query_embed).reshape(1, -1), 5)\n",
    "    scores = [\"[clip] {:.4f}\".format(s) for s in scores[0]]\n",
    "    ids = [ivl_desc_map[str(i)] for i in ids[0]]\n",
    "    res[f\"query_{idx}\"][en_query].append({\"text\": scores, \"image\": ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ReportMaker(\n",
    "    data_dict=res,\n",
    "    image_path=\"/data/local/multimodal_for_skb/images/skb\",\n",
    "    max_len=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm.make_report(\n",
    "    save_path=\"outputs/skb\",\n",
    "    save_name=\"multimodal_internvl_clip\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
